{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     d:\\Workspace\\personal\\ai_agent\\venv\\Lib\\site-\n",
      "[nltk_data]     packages\\llama_index\\core\\_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, PromptTemplate\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.core.output_parsers import PydanticOutputParser\n",
    "from llama_index.core.query_pipeline import QueryPipeline\n",
    "from prompts import context, code_parser_template\n",
    "from code_reader import code_reader\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import ast\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "LLAMAPARSE_API_KEY = os.environ.get(\"LLAMAPARSE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file d:\\Workspace\\personal\\ai_agent\\data\\readme.pdf with error: The event loop is already running. Add `import nest_asyncio; nest_asyncio.apply()` to your code to fix this issue.. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Workspace\\personal\\ai_agent\\venv\\Lib\\site-packages\\llama_index\\core\\readers\\file\\base.py:553: RuntimeWarning: coroutine 'LlamaParse.aload_data' was never awaited\n",
      "  return []\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\Workspace\\personal\\ai_agent\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the provided API, there are several routes defined:\n",
      "\n",
      "1. `/items` (HTTP methods: POST, GET) - Used for creating new items and retrieving all existing items.\n",
      "2. `/items/<int:item_id>` (HTTP methods: GET, PUT, DELETE) - Used for retrieving a specific item, updating an existing item with the given ID, or deleting an item with the given ID.\n",
      "   Note that the `<int:item_id>` part of the route indicates that the variable `item_id` should be an integer and will be automatically parsed from the requested URL.\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"mistral\", request_timeout=30.0)\n",
    "\n",
    "parser = LlamaParse(result_type=\"markdown\", api_key=LLAMAPARSE_API_KEY)\n",
    "file_extractor = {\".pdf\": parser}\n",
    "documents = SimpleDirectoryReader(\"./data\", file_extractor=file_extractor).load_data()\n",
    "\n",
    "embed_model = resolve_embed_model(\"local:BAAI/bge-m3\")\n",
    "vector_index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
    "query_engine = vector_index.as_query_engine(llm=llm)\n",
    "\n",
    "result = query_engine.query(\"what are some of the routes in the api?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse the response from a previous LLM into a description and a string of valid code, \n",
      "                            also come up with a valid filename this could be saved as that doesnt contain special characters. \n",
      "                            Here is the response: {response}. You should parse this in the following JSON Format: \n",
      "\n",
      "\n",
      "Here's a JSON schema to follow:\n",
      "{{\"properties\": {{\"code\": {{\"title\": \"Code\", \"type\": \"string\"}}, \"description\": {{\"title\": \"Description\", \"type\": \"string\"}}, \"filename\": {{\"title\": \"Filename\", \"type\": \"string\"}}}}, \"required\": [\"code\", \"description\", \"filename\"], \"title\": \"CodeOutput\", \"type\": \"object\"}}\n",
      "\n",
      "Output a valid JSON object but do not repeat the schema.\n",
      "\n",
      "##########################\n",
      "\n",
      "metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>} template_vars=['response'] kwargs={} output_parser=None template_var_mappings=None function_mappings=None template='Parse the response from a previous LLM into a description and a string of valid code, \\n                            also come up with a valid filename this could be saved as that doesnt contain special characters. \\n                            Here is the response: {response}. You should parse this in the following JSON Format: \\n\\n\\nHere\\'s a JSON schema to follow:\\n{{\"properties\": {{\"code\": {{\"title\": \"Code\", \"type\": \"string\"}}, \"description\": {{\"title\": \"Description\", \"type\": \"string\"}}, \"filename\": {{\"title\": \"Filename\", \"type\": \"string\"}}}}, \"required\": [\"code\", \"description\", \"filename\"], \"title\": \"CodeOutput\", \"type\": \"object\"}}\\n\\nOutput a valid JSON object but do not repeat the schema.\\n'\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"api_documentation\",\n",
    "            description=\"this gives documentation about code for an API. Use this for reading docs for the API\",\n",
    "        ),\n",
    "    ),\n",
    "    code_reader,\n",
    "]\n",
    "\n",
    "code_llm = Ollama(model=\"codellama\")\n",
    "agent = ReActAgent.from_tools(tools, llm=code_llm, verbose=True, context=context)\n",
    "\n",
    "class CodeOutput(BaseModel):\n",
    "    code: str\n",
    "    description: str\n",
    "    filename: str\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(CodeOutput)\n",
    "json_prompt_str = parser.format(code_parser_template)\n",
    "print(json_prompt_str)\n",
    "json_prompt_tmpl = PromptTemplate(json_prompt_str)\n",
    "print(\"##########################\\n\")\n",
    "print(json_prompt_tmpl)\n",
    "output_pipeline = QueryPipeline(chain=[json_prompt_tmpl, llm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 684e0773-36a4-48c6-94ae-ed81b3c2c73a. Step input: read the contents of test.py and write a python script that calls the post end point to make a new item.\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: Python. I need to use a tool to help me answer the question.\n",
      "Action: code_reader\n",
      "Action Input: {'file_name': 'test.py'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: {'file_content': 'from flask import Flask, request, jsonify\\n\\napp = Flask(__name__)\\n\\n# In-memory \"database\" for simplicity\\nitems = []\\n\\n\\n# Create\\n@app.route(\"/items\", methods=[\"POST\"])\\ndef create_item():\\n    data = request.get_json()\\n    items.append(data)\\n    return jsonify(data), 201\\n\\n\\n# Read all\\n@app.route(\"/items\", methods=[\"GET\"])\\ndef read_items():\\n    return jsonify(items)\\n\\n\\n# Read one\\n@app.route(\"/items/<int:item_id>\", methods=[\"GET\"])\\ndef read_item(item_id):\\n    if item_id < 0 or item_id >= len(items):\\n        return \"Item not found.\", 404\\n    return jsonify(items[item_id])\\n\\n\\n# Update\\n@app.route(\"/items/<int:item_id>\", methods=[\"PUT\"])\\ndef update_item(item_id):\\n    if item_id < 0 or item_id >= len(items):\\n        return \"Item not found.\", 404\\n    data = request.get_json()\\n    items[item_id] = data\\n    return jsonify(data)\\n\\n\\n# Delete\\n@app.route(\"/items/<int:item_id>\", methods=[\"DELETE\"])\\ndef delete_item(item_id):\\n    if item_id < 0 or item_id >= len(items):\\n        return \"Item not found.\", 404\\n    del items[item_id]\\n    return \"\", 204\\n\\n\\nif __name__ == \"__main__\":\\n    app.run(debug=True)\\n'}\n",
      "\u001b[0m> Running step 1b75a008-b8b8-458c-8c75-d81616156ccb. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: You can use the `requests` library in Python to make a POST request to the `/items` endpoint with the data you want to create an item for, and it will return the created item as JSON. Here is an example of how you can do this:\n",
      "```\n",
      "import requests\n",
      "\n",
      "# Data to create an item\n",
      "data = {\"name\": \"Item 1\", \"price\": 10.99}\n",
      "\n",
      "response = requests.post(\"http://localhost:5000/items\", json=data)\n",
      "print(response.json())\n",
      "```\n",
      "This will make a POST request to the `/items` endpoint with the data you provided in the `data` variable, and it will print the created item as JSON.\n",
      "\n",
      "You can also use the `requests` library to make GET requests to the `/items` and `/items/<int:item_id>` endpoints to read all items or a specific item by its ID, respectively. Here is an example of how you can do this:\n",
      "```\n",
      "import requests\n",
      "\n",
      "# Make a GET request to /items to read all items\n",
      "response = requests.get(\"http://localhost:5000/items\")\n",
      "print(response.json())\n",
      "\n",
      "# Make a GET request to /items/1 to read the item with ID 1\n",
      "response = requests.get(\"http://localhost:5000/items/1\")\n",
      "print(response.json())\n",
      "```\n",
      "This will make a GET request to the `/items` endpoint and print all items as JSON, and it will also make a GET request to the `/items/1` endpoint and print the item with ID 1 as JSON.\n",
      "\n",
      "You can also use the `requests` library to make PUT requests to the `/items/<int:item_id>` endpoint to update an existing item by its ID, and DELETE requests to the `/items/<int:item_id>` endpoint to delete an existing item by its ID. Here is an example of how you can do this:\n",
      "```\n",
      "import requests\n",
      "\n",
      "# Data to update an item\n",
      "data = {\"name\": \"Item 1 updated\", \"price\": 9.99}\n",
      "\n",
      "# Make a PUT request to /items/1 to update the item with ID 1\n",
      "response = requests.put(\"http://localhost:5000/items/1\", json=data)\n",
      "print(response.json())\n",
      "\n",
      "# Make a DELETE request to /items/1 to delete the item with ID 1\n",
      "response = requests.delete(\"http://localhost:5000/items/1\")\n",
      "print(response.json())\n",
      "```\n",
      "This will make a PUT request to the `/items/1` endpoint with the data you provided in the `data` variable, and it will print the updated item as JSON. It will also make a DELETE request to the `/items/1` endpoint and print the deleted item as JSON.\n",
      "\u001b[0mCode generated\n",
      "\n",
      "import requests\n",
      "\n",
      "# Data to create an item\n",
      "data = {\"name\": \"Item 1\", \"price\": 10.99}\n",
      "\n",
      "response = requests.post(\"http://localhost:5000/items\", json=data)\n",
      "print(response.json())\n",
      "\n",
      "# Make a GET request to /items to read all items\n",
      "response = requests.get(\"http://localhost:5000/items\")\n",
      "print(response.json())\n",
      "\n",
      "# Make a GET request to /items/1 to read the item with ID 1\n",
      "response = requests.get(\"http://localhost:5000/items/1\")\n",
      "print(response.json())\n",
      "\n",
      "# Data to update an item\n",
      "data_update = {\"name\": \"Item 1 updated\", \"price\": 9.99}\n",
      "\n",
      "# Make a PUT request to /items/1 to update the item with ID 1\n",
      "response = requests.put(\"http://localhost:5000/items/1\", json=data_update)\n",
      "print(response.json())\n",
      "\n",
      "# Make a DELETE request to /items/1 to delete the item with ID 1\n",
      "response = requests.delete(\"http://localhost:5000/items/1\")\n",
      "print(response.json())\n",
      "\n",
      "\n",
      "\n",
      "Desciption: Python code using the `requests` library to perform CRUD operations on an API's `/items` endpoint.\n",
      "Saved file api_crud_example.py\n"
     ]
    }
   ],
   "source": [
    "while (prompt := input(\"Enter a prompt (q to quit): \")) != \"q\":     #   read the contents of test.py and write a python script that calls the post end point to make a new item.\n",
    "    retries = 0\n",
    "\n",
    "    while retries < 3:\n",
    "        try:\n",
    "            result = agent.query(prompt)\n",
    "            next_result = output_pipeline.run(response=result)\n",
    "            cleaned_json = ast.literal_eval(str(next_result).replace(\"assistant:\", \"\"))\n",
    "            break\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            print(f\"Error occured, retry #{retries}:\", e)\n",
    "\n",
    "    if retries >= 3: \n",
    "        print(\"Unable to process request, try again...\")\n",
    "        continue\n",
    "\n",
    "    print(\"Code generated\")\n",
    "    print(cleaned_json[\"code\"])\n",
    "    print(\"\\n\\nDesciption:\", cleaned_json[\"description\"])\n",
    "\n",
    "    filename = cleaned_json[\"filename\"]\n",
    "\n",
    "    try:\n",
    "        with open(os.path.join(\"output\", filename), \"w\") as f:\n",
    "            f.write(cleaned_json[\"code\"])\n",
    "        print(\"Saved file\", filename)\n",
    "    except:\n",
    "        print(\"Error saving file...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example from https://docs.llamaindex.ai/en/stable/examples/pipeline/query_pipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module 9cbbc324-8b56-43f6-810e-9f94261efa87 with input: \n",
      "movie_name: Toy Story\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module d71851e4-6fec-41fa-b2b9-6de22adde033 with input: \n",
      "messages: \n",
      "Please generate related movies to Toy Story. Output with the following JSON format: \n",
      "\n",
      "\n",
      "\n",
      "Here's a JSON schema to follow:\n",
      "{\"$defs\": {\"Movie\": {\"description\": \"Object representing a single movie.\", \"pro...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 3ee04f56-4525-401a-a42d-7ad508bac602 with input: \n",
      "input: assistant: {\n",
      "  \"movies\": [\n",
      "    {\n",
      "      \"name\": \"Finding Nemo\",\n",
      "      \"year\": 2003\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Cars\",\n",
      "      \"year\": 2006\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Up\",\n",
      "      \"year\": 2009\n",
      "    },\n",
      "    {...\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Movies(movies=[Movie(name='Finding Nemo', year=2003), Movie(name='Cars', year=2006), Movie(name='Up', year=2009), Movie(name='Inside Out', year=2015)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Movie(BaseModel):\n",
    "    \"\"\"Object representing a single movie.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"Name of the movie.\")\n",
    "    year: int = Field(..., description=\"Year of the movie.\")\n",
    "\n",
    "\n",
    "class Movies(BaseModel):\n",
    "    \"\"\"Object representing a list of movies.\"\"\"\n",
    "\n",
    "    movies: List[Movie] = Field(..., description=\"List of movies.\")\n",
    "\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")        # Local version of Ollama doesn't work.\n",
    "\n",
    "output_parser = PydanticOutputParser(Movies)\n",
    "json_prompt_str = \"\"\"\n",
    "Please generate related movies to {movie_name}. Output with the following JSON format: \n",
    "\"\"\"\n",
    "json_prompt_str = output_parser.format(json_prompt_str)  \n",
    "\n",
    "# add JSON spec to prompt template\n",
    "json_prompt_tmpl = PromptTemplate(json_prompt_str)\n",
    "\n",
    "p = QueryPipeline(chain=[json_prompt_tmpl, llm, output_parser], verbose=True)\n",
    "output = p.run(movie_name=\"Toy Story\")\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
